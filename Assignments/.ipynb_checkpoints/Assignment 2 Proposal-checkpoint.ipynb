{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME:\n",
    "## EMAIL:\n",
    "## GROUP:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "\n",
    "You may work in groups, but you must submit your own work. If you worked with others, please be sure to include their names in your submitted work in your submitted jupyter notebook. \n",
    "\n",
    "Be sure to **DOCUMENT your work** (points will be deducted without documentation). Always import any packages that you use at the top of your assignment. \n",
    "\n",
    "Be sure to include your name and email address in the jupyter notebook that you turn in.  \n",
    "\n",
    "Use the power of the internet when you're stuck or need to find a function to execute it. **CITE YOU WORK when you do this** (points will be deducted without citations)\n",
    "\n",
    "Use this notebook as your template and fill your code (if asked) in the designated area. Email me your jupyter notebook directly (ends with .ipynb). You can attach it like any other file. \n",
    "\n",
    "Deadlines are posted in the announcement section on Blackboard.\n",
    "\n",
    "If a question is unclear about what I am asking, ask it in your classroom discussion board and I will answer it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This assignment consists of **two parts**:\n",
    "\n",
    "## Part 1: Coding exercises (60 points)\n",
    "\n",
    "You have 4 questions that you must answer (15 points each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Use the [pokeAPI](https://pokeapi.co/)\n",
    "\n",
    "Find out information about the Pokemon \"Gible\":\n",
    "- What is its type(s)?\n",
    "- What is its abilities?\n",
    "\n",
    "You must use python and apply the GET method via their API to display this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Use the [pokeAPI](https://pokeapi.co/) to find out:\n",
    "\n",
    "How many pokemon are \"dragon\" type?\n",
    "\n",
    "You mut use python and apply the GET method via their API and display this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Use the [Open Air Quality API](https://docs.openaq.org/)\n",
    "\n",
    "Hint: typically queries need a ? in the url\n",
    "\n",
    "Find out how much ozone there is near CCNY. Use the most recent date that you pull the information.\n",
    "\n",
    "You mut use python and apply the GET method via their API and display this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Use the [Open Air Quality API](https://docs.openaq.org/)\n",
    "\n",
    "Hint: typically queries need a ? in the url. Note that cities that need a space use a %20 between them (ie Los%20Angeles). Make sure that when you request information about a measurement that you are using a url that can do this for you.\n",
    "\n",
    "First find out what the parameter id is of 'Particulate matter less than 10 micrometers in diameter.'\n",
    "\n",
    "Then, find out how much 'Particulate matter less than 10 micrometers in diameter' there is in:\n",
    "- Beijing\n",
    "- Amsterdam\n",
    "- Addis Ababa\n",
    "- Melbourne\n",
    "- Hyderabad\n",
    "\n",
    "Bonus points if you can aggregate this information in one table.\n",
    "\n",
    "You mut use python and apply the GET method via their API and display this information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Your proposal of data that you'd like to collect (40 points)\n",
    "\n",
    "You must pick data that you would like to collect for web-scraping - the data **MUST** come from APIs (none of this download csv stuff). The data set will be your final project. You can ammend and make changes later to data sources and variables. Get creative!\n",
    "\n",
    "Be mindful of the timeline - ambitious project can't be completed in 2 months, but a snapshot of it can be done. \n",
    "\n",
    "You must pick one variable that does not exist yet or is not obviously common. The variable should either be web-scraped or if it is from an API, it must be calculated (and not very common). For example, Songs per capita is commmon - you might have to calculate it, but it doesn't count. Genre concentration by state is a variable that is acceptable. Remember only **ONE** variable has to be calculated/webscraped, but you will need a total of 3 variables.\n",
    "\n",
    "In the final project, you will be providing your code and documentation (not this assignment). I will test the code you give me to make sure it runs.\n",
    "\n",
    "For my sanity - format the proposal to be organized in this jupyter notebook. Include graphs, photos, examples, etc. But, please make it look professional and clean. The easier it is to read, the easier it is for me to grade, and better outcomes will likely follow.\n",
    "\n",
    "This is a proposal, so you do not have to collect the data now.\n",
    "\n",
    "In your proposal you must include:\n",
    "1. Identify the website/API that you will be web-scraping data from. You can also suggest a variety of websites via web crawling (for example, if you want to crawl websites of selected non-profit organizations and collect information about the board members - this is doable.)\n",
    "2. Define at least 3 variables that you will be collecting. You can only web-scrape/calculate from an API *ONE* variable so long as you are combining this data with other data sources. You must list those other data source variables.\n",
    "3. If it is an open access API, get an authorization key (if neccessary), if it is not needed, also note that. Provide evidence of this with screen shot that you obtained said key or a link (and a summary in your proposal) of the documentation that says it's freely accessible.\n",
    "4. If it is not an open access API, ensure that you meet the terms and conditions (there is wiggle room here - but, if you are trying to crack a google related non-open access API, that's unreasonable and not possible in this class. However, if it is a Google/Amazon/InsertBigTechComp with open access API - that is do-able!). Most websites have terms and conditions, include a link to this information and briefly (a few sentences) describe what you can or can't get access to.\n",
    "5. Identify your research question - what are you going to analyze? Remember that after getting the data, you will make meaningful graphs and run regressions with it. \n",
    "6. Give me a bit of background and motivation. Why are you scraping this data? Why should you research/study this question?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
